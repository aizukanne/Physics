### 1.4 Errors and Uncertainties
No measurement is perfectly exact. There is always some degree of uncertainty associated with any measured value. Understanding and quantifying this uncertainty is crucial in experimental science.

**Types of Errors:**

Errors in measurement refer to the difference between the measured value and the true value of the quantity. They can generally be categorized into two types:

1.  **Systematic Errors:** These errors consistently affect measurements in the same direction (either always too high or always too low). They are often due to faulty equipment (e.g., a miscalibrated scale, a zero error on a meter rule) or flawed experimental procedure. Systematic errors cannot be reduced by repeating measurements. They must be identified and eliminated or corrected for.
    *   *Example:* A thermometer that consistently reads 2°C higher than the actual temperature.
    *   *Example:* Measuring reaction time with a stopwatch but consistently starting it slightly late.
2.  **Random Errors:** These errors cause unpredictable fluctuations in measurements, resulting in readings that are sometimes too high and sometimes too low. They arise from limitations in the measuring instrument, environmental fluctuations, or variations in observer judgment. Random errors can be reduced by taking multiple readings and calculating an average.
    *   *Example:* Fluctuations in reading the meniscus level in a burette due to parallax or unsteady hands.
    *   *Example:* Variations in timing an oscillation due to inconsistent start/stop points.

**Accuracy vs. Precision:**

These terms are often confused but have distinct meanings in measurement:

*   **Accuracy:** How close a measured value is to the *true* or accepted value. High accuracy implies small systematic errors.
*   **Precision:** How close repeated measurements of the same quantity are to *each other*. High precision implies small random errors.

It's possible to have measurements that are:
*   Accurate and Precise (ideal)
*   Precise but Inaccurate (consistent error, e.g., systematic error)
*   Accurate but Imprecise (average is close to true value, but readings are scattered)
*   Inaccurate and Imprecise (worst case)

**Estimating Uncertainty:**

Since the true value is often unknown, we estimate the uncertainty in our measurements.

*   **Single Reading:** For analogue instruments, the uncertainty is often taken as ± half the smallest division on the scale. For digital instruments, it's often ± the smallest increment displayed.
    *   *Example:* A ruler marked in millimeters (0.1 cm). A reading might be recorded as 12.3 cm ± 0.05 cm.
    *   *Example:* A digital voltmeter reading 1.54 V might have an uncertainty of ± 0.01 V.
*   **Multiple Readings:** When multiple readings (`x₁, x₂, ..., x<0xE2><0x82><0x99>`) are taken to reduce random error, the best estimate of the true value is the mean (`x̄`). The uncertainty can be estimated from the range of the readings (often `± (maximum reading - minimum reading) / 2`).

**Significant Figures:**

Significant figures (or significant digits) indicate the precision of a measured value. They include all the digits known with certainty plus one uncertain or estimated digit.

*   **Rules for Identifying Significant Figures:**
    1.  Non-zero digits are always significant. (e.g., `23.4` has 3 s.f.)
    2.  Zeros between non-zero digits are significant. (e.g., `5007` has 4 s.f.)
    3.  Leading zeros (before the first non-zero digit) are *not* significant. (e.g., `0.0032` has 2 s.f.)
    4.  Trailing zeros are significant *only* if the number contains a decimal point. (e.g., `120.` has 3 s.f., `120` has 2 s.f., `0.0250` has 3 s.f.)
*   **Calculations with Significant Figures:**
    *   **Multiplication/Division:** The result should have the same number of significant figures as the measurement with the *fewest* significant figures.
    *   **Addition/Subtraction:** The result should have the same number of *decimal places* as the measurement with the *fewest* decimal places.

**Propagation of Uncertainties (Basic Introduction):**

When measured quantities with uncertainties are used in calculations, the uncertainty propagates to the final result. Simple rules for estimating the uncertainty in the result include:

*   **Addition/Subtraction:** Add the *absolute* uncertainties. If `y = a + b` or `y = a - b`, then `Δy ≈ Δa + Δb`.
*   **Multiplication/Division:** Add the *percentage* (or fractional) uncertainties. If `y = a × b` or `y = a / b`, then `(Δy/y) ≈ (Δa/a) + (Δb/b)`.

(More detailed rules exist, but these provide a basic estimate. This topic is often explored further in practical skills sections.)